{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668afaea-15cf-4776-a1e1-70f08d6687d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "from data_preprocessing import import_data\n",
    "from data_preprocessing import split_data\n",
    "from data_preprocessing import CreateDataset\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbff5b4a-25b3-485e-a0bf-a4b3e0263495",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CasperNet(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(CasperNet, self).__init__()\n",
    "        self.total_neurons = input_dim + output_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden_dim = input_dim # dimension of the hidden layer (dimension of the cascased input)\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim) # start with minimal network\n",
    "        self.hidden_layers = nn.ModuleList() # maintain a list of hidden layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        # loop through all hidden layer, cascade to inputs\n",
    "        for layer in self.hidden_layers:\n",
    "            hidden_output = self.relu(layer(x)) # output of a hidden unit\n",
    "            x = torch.cat((x, hidden_output), dim=1)  # cascade the output to the previous inputs\n",
    "        \n",
    "        return self.sigmoid(self.output_layer(x))\n",
    "\n",
    "    \n",
    "    def add_neuron(self):\n",
    "        new_neuron = nn.Linear(self.hidden_dim, 1)\n",
    "        self.hidden_dim += 1 # update hidden layer dimension\n",
    "        self.total_neurons += 1\n",
    "        self.hidden_layers.append(new_neuron) # add the candidate to the hidden unit list\n",
    "        \n",
    "        \n",
    "        # Preserve old weights and biases\n",
    "        old_weights = self.output_layer.weight.data\n",
    "        old_biases = self.output_layer.bias.data\n",
    "    \n",
    "        # Create new output layer\n",
    "        self.output_layer = nn.Linear(self.hidden_dim, self.output_dim)\n",
    "    \n",
    "        # Assign old weights and biases back\n",
    "        self.output_layer.weight.data[:, :-1] = old_weights\n",
    "        self.output_layer.bias.data = old_biases\n",
    "        \n",
    "        # Initialize the new weights (last column) - using xavier initialization as an example\n",
    "        nn.init.xavier_uniform_(self.output_layer.weight.data[:, -1].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c650fdf-8e37-4065-9ace-7e510b8d6f5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_network(model, train_data, optimiser, min_epoch, threshold, P):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    epoch = 1\n",
    "    prev_train_loss = float('inf')\n",
    "    train_loss = 0\n",
    "    \n",
    "    threshold_P = 0 # how many times does the model fall below the threshold\n",
    "    threshold_P_max = 15 + model.total_neurons * P # stop training if threshold_P exceed this value\n",
    "    \n",
    "    while True:\n",
    "        correct = 0 # total correct predictions      \n",
    "        \n",
    "        train_input = train_data.iloc[:, 1:]\n",
    "        train_target = train_data.iloc[:, 0]\n",
    "        inputs = torch.Tensor(train_input.values).float()\n",
    "        labels = torch.Tensor(train_target.values).long()\n",
    "        \n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        train_loss = loss.item()\n",
    "            \n",
    "        # calculate accuracy\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += sum(predicted.data.numpy() == labels.data.numpy())\n",
    "        \n",
    "        \n",
    "        if prev_train_loss != float('inf'):\n",
    "            percent = abs((prev_train_loss - train_loss) / prev_train_loss)\n",
    "        else:\n",
    "            percent = 1\n",
    "        \n",
    "        # print loss and accuracy\n",
    "        if (epoch % 50) == 0 or epoch - 1 == 0:\n",
    "            accuracy = correct / len(train_data) * 100\n",
    "            print(f'Epoch {epoch}, Loss: {train_loss:.4f}, Accuracy: {accuracy:.4f} %')\n",
    "        \n",
    "        \n",
    "        if percent < threshold:\n",
    "            threshold_P += 1\n",
    "            \n",
    "        \n",
    "        # print(percent, prev_train_loss, train_loss)\n",
    "        # print(threshold_P, threshold_P_max)\n",
    "        \n",
    "        # if epoch >= min_epoch:\n",
    "        #     break \n",
    "        \n",
    "        if threshold_P >= threshold_P_max:\n",
    "            break                          \n",
    "        \n",
    "        prev_train_loss = train_loss\n",
    "        epoch += 1\n",
    "\n",
    "    print(f'Training stop at epoch {epoch} with loss = {train_loss:.4f}')\n",
    "    return train_loss\n",
    "\n",
    "\n",
    "def print_params(model):\n",
    "    for p in model.parameters():\n",
    "        is_frozen = \"Frozen \" if not p.requires_grad else \"Trainable \"\n",
    "        print(f'{is_frozen} {p.data} {p.data.shape}')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97f839d0-e4e7-49f0-85ce-6db5000aa5d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, update_optimiser, min_iter, min_epoch, threshold = 0.0001, P = 1):\n",
    "    \n",
    "    iteration = 1\n",
    "    \n",
    "    # keep adding neuron to the network\n",
    "    while(True):\n",
    "        # train the network\n",
    "        optimiser = update_optimiser(model)\n",
    "        train_network(model, train_data, optimiser, min_epoch, threshold, P)\n",
    "        \n",
    "        if iteration >= min_iter:\n",
    "            break\n",
    "        iteration += 1\n",
    "        \n",
    "        # add an neuron\n",
    "        model.add_neuron()\n",
    "        # print_params(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2be4b042-0966-42e1-935d-6890372be925",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# test the model (modified from lab 2)\n",
    "def test(model, train_data, test_data):\n",
    "    model.eval()\n",
    "    \n",
    "    # test on train set\n",
    "    train_input = train_data.iloc[:, 1:]\n",
    "    train_target = train_data.iloc[:, 0]\n",
    "    inputs = torch.Tensor(train_input.values).float()\n",
    "    targets = torch.Tensor(train_target.values).long()\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(\"Confusion matrix for training:\")\n",
    "    print(confusion_matrix(targets.data, predicted.cpu().long().data))\n",
    "\n",
    "    # test on test set\n",
    "    test_input = test_data.iloc[:, 1:]\n",
    "    test_target = test_data.iloc[:, 0]\n",
    "    inputs = torch.Tensor(test_input.values).float()\n",
    "    targets = torch.Tensor(test_target.values).long()\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    print(\"Confusion matrix for testing:\")\n",
    "    print(confusion_matrix(targets.data, predicted.cpu().long().data))\n",
    "    \n",
    "    # print test accuracy\n",
    "    total = predicted.size(0)\n",
    "    correct = predicted.cpu().data.numpy() == targets.data.numpy()\n",
    "    print('Testing Accuracy: %.2f %%' % (100 * sum(correct)/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7557cb39-b17d-48d7-839d-0d60ebfad948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomRprop(optim.Rprop):\n",
    "    def __init__(self, params, lr=1e-2, etas=(0.5, 1.2), step_sizes=(1e-6, 50), D=0.01, T=1, *args, **kwargs):\n",
    "        super(CustomRprop, self).__init__(params, lr, etas, step_sizes, *args, **kwargs)\n",
    "        \n",
    "        # Additional parameters for weight decay\n",
    "        self.D = D\n",
    "        self.T = T\n",
    "        self.H_epoch = 0  # Initialize epoch count\n",
    "        \n",
    "    def step(self, closure=None):\n",
    "        # Increment epoch count\n",
    "        self.H_epoch += 1\n",
    "        \n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            with torch.enable_grad():\n",
    "                loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                \n",
    "                grad = p.grad.data\n",
    "                state = self.state[p]\n",
    "                \n",
    "                # Your custom weight decay term\n",
    "                weight_decay_term = -self.D * torch.sign(p.data) * p.data**2 * (2**(-self.T * self.H_epoch))\n",
    "                \n",
    "                # Apply the weight decay to the gradient\n",
    "                grad.add_(weight_decay_term)\n",
    "                \n",
    "                # Rest of the Rprop logic remains the same...\n",
    "\n",
    "        # Call the parent's step method to apply the modified gradient\n",
    "        super(CustomRprop, self).step(closure)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad680ff0-dd9f-499b-9316-bc9aac31c124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_optimiser_parameters(model, lr_l1, lr_l2, lr_l3):\n",
    "    param_l1 = []\n",
    "    param_l3 = []\n",
    "    \n",
    "    param_l2 = [list(model.output_layer.parameters())[0]]\n",
    "    param_l3.append(list(model.output_layer.parameters())[1]) # bias of output neurons is L3\n",
    "    \n",
    "    if len(model.hidden_layers) != 0:\n",
    "        param_l1 = [list(model.hidden_layers[-1].parameters())[0]] # weights of the new hidden neuron is L1\n",
    "        param_l3.extend(list(model.hidden_layers[:-1].parameters())) # weights and bias of the other hidden neurons are L3\n",
    "        param_l3.append(list(model.hidden_layers[-1].parameters())[1]) # bias of the new hidden neuron is L3\n",
    "        \n",
    "\n",
    "    \n",
    "    # Create parameter groups\n",
    "    parameters = [\n",
    "        {\"params\": param_l1, \"lr\": lr_l1},\n",
    "        {\"params\": param_l2, \"lr\": lr_l2},\n",
    "        {\"params\": param_l3, \"lr\": lr_l3},\n",
    "    ]\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb880f3e-01d0-4f79-981e-5238d628f029",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.1047, Accuracy: 33.6538 %\n",
      "Epoch 50, Loss: 0.8593, Accuracy: 58.1731 %\n",
      "Epoch 100, Loss: 0.8327, Accuracy: 58.6538 %\n",
      "Epoch 150, Loss: 0.8244, Accuracy: 57.6923 %\n",
      "Epoch 200, Loss: 0.8197, Accuracy: 55.7692 %\n",
      "Training stop at epoch 227 with loss = 0.8181\n",
      "Epoch 1, Loss: 0.8180, Accuracy: 55.7692 %\n",
      "Epoch 50, Loss: 0.8142, Accuracy: 57.2115 %\n",
      "Training stop at epoch 73 with loss = 0.8131\n",
      "Epoch 1, Loss: 0.8132, Accuracy: 56.2500 %\n",
      "Epoch 50, Loss: 0.8092, Accuracy: 56.7308 %\n",
      "Training stop at epoch 71 with loss = 0.8082\n",
      "Epoch 1, Loss: 0.8081, Accuracy: 56.2500 %\n",
      "Epoch 50, Loss: 0.8040, Accuracy: 55.7692 %\n",
      "Training stop at epoch 81 with loss = 0.8019\n",
      "Confusion matrix for training:\n",
      "[[47 13  5]\n",
      " [24 38 12]\n",
      " [ 9 28 32]]\n",
      "Confusion matrix for testing:\n",
      "[[12  2  3]\n",
      " [ 1  9  8]\n",
      " [ 2 10  6]]\n",
      "Testing Accuracy: 50.94 %\n"
     ]
    }
   ],
   "source": [
    "# make results determinstic\n",
    "seed = 4660\n",
    "if seed != None:\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Define hyperparameter\n",
    "input_size = None\n",
    "num_classes = None\n",
    "num_epochs = 500\n",
    "batch_size = 10\n",
    "num_candidates = 5\n",
    "max_iter = 4\n",
    "\n",
    "lr_1 = 0.2\n",
    "lr_2 = 0.005\n",
    "lr_3 = 0.001\n",
    "\n",
    "# import data\n",
    "data, num_classes, input_size = import_data()\n",
    "\n",
    "# randomly split data into training set (80%) and testing set (20%)\n",
    "train_data, test_data = split_data(data, seed = None)\n",
    "\n",
    "# initialise network\n",
    "casper_net = CasperNet(input_size, num_classes)\n",
    "\n",
    "\n",
    "# initialise optimiser (since network structure is changing, we need to update our optimiser frequently)\n",
    "def update_optimiser(model):\n",
    "    optimiser_parameters = get_optimiser_parameters(model, lr_1, lr_2, lr_3)\n",
    "    return CustomRprop(optimiser_parameters)\n",
    "\n",
    "\n",
    "# train the model\n",
    "# train(simple_nn, train_loader, num_epochs, optimiser)\n",
    "train(casper_net, train_data, update_optimiser, max_iter, num_epochs)\n",
    "\n",
    "# test the model\n",
    "test(casper_net, train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b8099d-5a36-4f2c-bca7-5ea04bc840c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fba578-1841-49de-a21b-6469a29e8d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
